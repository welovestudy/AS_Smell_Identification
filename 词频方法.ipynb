{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.root.handlers = []  # Jupyter messes up logging so needs a reset\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import linear_model\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_prediction(predictions, target, title=\"Confusion matrix\"):\n",
    "    print('accuracy %s' % accuracy_score(target, predictions))\n",
    "    print('precision %s' % precision_score(target, predictions))\n",
    "    print('recall %s' % recall_score(target, predictions))\n",
    "    print('F1 %s' % f1_score(target, predictions))\n",
    "def plot_confusion_matrix(cm, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(my_tags))\n",
    "    target_names = my_tags\n",
    "    plt.xticks(tick_marks, target_names, rotation=45)\n",
    "    plt.yticks(tick_marks, target_names)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "def predict(vectorizer, classifier, data):\n",
    "    data_features = vectorizer.transform(data[test_slice])\n",
    "    predictions = classifier.predict(data_features)\n",
    "    target = data['tag']\n",
    "    evaluate_prediction(predictions, target)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "def ten_cross_fold_predict(vectorizer, classifier, df):\n",
    "    n = 5\n",
    "    train_feature = vectorizer.fit_transform(df[test_slice])\n",
    "    y = df['tag']\n",
    "    print('accuracy %s' % np.mean(cross_val_score(classifier, train_feature, y, scoring='accuracy', cv=n)))\n",
    "    print('precision %s' % np.mean(cross_val_score(classifier, train_feature, y, scoring='precision', cv=n)))\n",
    "    print('recall %s' % np.mean(cross_val_score(classifier, train_feature, y, scoring='recall', cv=n)))\n",
    "    print('F1 %s' % np.mean(cross_val_score(classifier, train_feature, y, scoring='f1', cv=n)))\n",
    "    \n",
    "def most_influential_words(vectorizer, genre_index=0, num_words=10):\n",
    "    features = vectorizer.get_feature_names()\n",
    "    max_coef = sorted(enumerate(logreg.coef_[genre_index]), key=lambda x:x[1], reverse=True)\n",
    "    return [features[x[0]] for x in max_coef[:num_words]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# nltk.download('wordnet')\n",
    "from nltk.stem import SnowballStemmer  \n",
    "snowball_stemmer = SnowballStemmer(\"english\")  \n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "lmtzr = WordNetLemmatizer()\n",
    "# lmtzr.lemmatize('cars')\n",
    "# snowball_stemmer.stem(\"maximum\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_slice(index): \n",
    "    example = df[df.index == index][[test_slice, 'tag']].values[0]\n",
    "    if len(example) > 0:\n",
    "        print(example[0])\n",
    "        print('Genre:', example[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('data/AS_smell_singleanswer.csv')\n",
    "df2 = pd.read_csv('data/non_AS_smell_singleanswer_utf8.csv')\n",
    "df = pd.concat([df1,df2])\n",
    "df = df.dropna()\n",
    "df['total'] = df['tittle'] + df['question'] + df['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_slice = 'total'\n",
    "train_data, test_data = train_test_split(df, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(395):\n",
    "    text = df.iloc[i,6]\n",
    "    remove = str.maketrans('','',string.punctuation) \n",
    "    df.iloc[i,6] = text.translate(remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What would be a nice architecture so I can pass information of eventual problems to a higher layerI have a standard 3 layer project and my data layer either accesses the database or an API I would like to be able to show information to the user in case there are problems occurring in the data layer\n",
      "I would like to show in the interface if there was any error some required info by the API was not set problems connecting to the databaseAPI or any other problem that could happen\n",
      "Currently I would have an out string error parameter that would return the problem message But this smells bad and this will also require my business layer to have the same paramter which smells even worse\n",
      "What would be a nice architecture so I can pass information of eventual problems to a higher layer \n",
      "ThanksThere could be two ways\n",
      "\n",
      "Raising some custom exception\n",
      "Raising event at database layer and handle it in business layer\n",
      "\n",
      "Now while raising the eventexception at data layer you can pass the information which will help you in business layer\n",
      "The only change at business layer will be the listening of these events or catching these exceptions\n",
      "Genre: 1\n"
     ]
    }
   ],
   "source": [
    "# stem/lemmma前\n",
    "\n",
    "print_slice(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'start'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowball_stemmer.stem(\"started\") \n",
    "# lmtzr.lemmatize('Currently')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(395):\n",
    "    text = df.iloc[i,6]\n",
    "    remove = str.maketrans('','',string.punctuation) \n",
    "    df.iloc[i,6] = snowball_stemmer.stem(df.iloc[i,6])\n",
    "    df.iloc[i,6] = lmtzr.lemmatize(df.iloc[i,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what would be a nice architecture so i can pass information of eventual problems to a higher layeri have a standard 3 layer project and my data layer either accesses the database or an api i would like to be able to show information to the user in case there are problems occurring in the data layer\n",
      "i would like to show in the interface if there was any error some required info by the api was not set problems connecting to the databaseapi or any other problem that could happen\n",
      "currently i would have an out string error parameter that would return the problem message but this smells bad and this will also require my business layer to have the same paramter which smells even worse\n",
      "what would be a nice architecture so i can pass information of eventual problems to a higher layer \n",
      "thanksthere could be two ways\n",
      "\n",
      "raising some custom exception\n",
      "raising event at database layer and handle it in business layer\n",
      "\n",
      "now while raising the eventexception at data layer you can pass the information which will help you in business layer\n",
      "the only change at business layer will be the listening of these events or catching these except\n",
      "Genre: 1\n"
     ]
    }
   ],
   "source": [
    "# stem/lemmma后\n",
    "\n",
    "print_slice(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TD-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_vect = TfidfVectorizer(\n",
    "    min_df=2, tokenizer=nltk.word_tokenize,\n",
    "    preprocessor=None, stop_words='english')\n",
    "train_data_features = tf_vect.fit_transform(train_data[test_slice])  ## lack of nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(train_data_features.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #logistic\n",
    "# logreg = linear_model.LogisticRegression(n_jobs=1, C=1e5)\n",
    "# logreg = logreg.fit(train_data_features, train_data['tag'])\n",
    "\n",
    "# # SVM\n",
    "# from sklearn import svm\n",
    "# svc = svm.SVC(gamma='scale')\n",
    "# svc = svc.fit(train_data_features, train_data['tag'])\n",
    "\n",
    "# #random forest\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# rf = RandomForestClassifier(n_estimators=10)\n",
    "# rf = rf.fit(train_data_features, train_data['tag'])\n",
    "\n",
    "# # knn\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# knn = KNeighborsClassifier(n_neighbors=3, n_jobs=1, algorithm='brute', metric='cosine' )\n",
    "# knn.fit(train_data_features, train_data['tag'])\n",
    "\n",
    "\n",
    "\n",
    "# # predict\n",
    "# predict(tf_vect, logreg, test_data)\n",
    "# predict(tf_vect, svc, test_data)\n",
    "# predict(tf_vect, rf, test_data)\n",
    "# predict(tf_vect, knn, test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lf/PycharmProjects/ASsmell/venv/lib/python3.8/site-packages/sklearn/linear_model/logistic.py:430: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  warnings.warn(\"Default solver will be changed to 'lbfgs' in 0.22. \"\n",
      "/Users/lf/PycharmProjects/ASsmell/venv/lib/python3.8/site-packages/sklearn/linear_model/logistic.py:430: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  warnings.warn(\"Default solver will be changed to 'lbfgs' in 0.22. \"\n",
      "/Users/lf/PycharmProjects/ASsmell/venv/lib/python3.8/site-packages/sklearn/linear_model/logistic.py:430: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  warnings.warn(\"Default solver will be changed to 'lbfgs' in 0.22. \"\n",
      "/Users/lf/PycharmProjects/ASsmell/venv/lib/python3.8/site-packages/sklearn/linear_model/logistic.py:430: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  warnings.warn(\"Default solver will be changed to 'lbfgs' in 0.22. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.5873231093800715\n",
      "precision 0.6152645502645503\n",
      "recall 0.6101045296167247\n",
      "F1 0.6064296421096863\n",
      "accuracy 0.5876760791950665\n",
      "precision 0.5889177639177638\n",
      "recall 0.5480836236933798\n",
      "F1 0.5876533544347333\n",
      "accuracy 0.6199829600778968\n",
      "precision 0.6188633879781421\n",
      "recall 0.7499419279907084\n",
      "F1 0.6746822696660886\n",
      "accuracy 0.5723239208049333\n",
      "precision 0.5911895424836601\n",
      "recall 0.6058072009291522\n",
      "F1 0.5942607986092633\n"
     ]
    }
   ],
   "source": [
    "# 10_fold_predict\n",
    "\n",
    "svc_10 = svm.SVC(gamma='scale')\n",
    "rf_10 = RandomForestClassifier(n_estimators=10)\n",
    "logreg_10 = linear_model.LogisticRegression(n_jobs=1, C=1e5)\n",
    "knn_10 = KNeighborsClassifier(n_neighbors=3, n_jobs=1, algorithm='brute', metric='cosine' )\n",
    "ten_cross_fold_predict(tf_vect, logreg_10, df)\n",
    "ten_cross_fold_predict(tf_vect, rf_10, df)\n",
    "ten_cross_fold_predict(tf_vect, svc_10, df)\n",
    "ten_cross_fold_predict(tf_vect, knn_10, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(text):\n",
    "    tokens = []\n",
    "    for sent in nltk.sent_tokenize(text):\n",
    "        for word in nltk.word_tokenize(sent):\n",
    "            if len(word) < 3:\n",
    "                continue\n",
    "            tokens.append(word.lower())\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "count_vectorizer = CountVectorizer(\n",
    "    analyzer=\"word\", tokenizer=nltk.word_tokenize,\n",
    "    preprocessor=None, stop_words='english', max_features=3000) \n",
    "train_data_features = count_vectorizer.fit_transform(train_data[test_slice])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lf/PycharmProjects/ASsmell/venv/lib/python3.8/site-packages/sklearn/linear_model/logistic.py:430: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  warnings.warn(\"Default solver will be changed to 'lbfgs' in 0.22. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.5\n",
      "precision 0.5238095238095238\n",
      "recall 0.5238095238095238\n",
      "F1 0.5238095238095238\n",
      "\n",
      "\n",
      "accuracy 0.45\n",
      "precision 0.48484848484848486\n",
      "recall 0.7619047619047619\n",
      "F1 0.5925925925925926\n",
      "\n",
      "\n",
      "accuracy 0.575\n",
      "precision 0.5833333333333334\n",
      "recall 0.6666666666666666\n",
      "F1 0.6222222222222222\n",
      "\n",
      "\n",
      "accuracy 0.525\n",
      "precision 0.5416666666666666\n",
      "recall 0.6190476190476191\n",
      "F1 0.5777777777777778\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# logistic\n",
    "logreg = linear_model.LogisticRegression(n_jobs=1, C=1e5)\n",
    "logreg = logreg.fit(train_data_features, train_data['tag'])\n",
    "\n",
    "# SVC\n",
    "svc = svm.SVC(gamma='scale')\n",
    "svc = svc.fit(train_data_features, train_data['tag'])\n",
    "\n",
    "# randomforest\n",
    "rf = RandomForestClassifier(n_estimators=10)\n",
    "rf = rf.fit(train_data_features, train_data['tag'])\n",
    "\n",
    "# knn\n",
    "knn = KNeighborsClassifier(n_neighbors=3, n_jobs=1, algorithm='brute', metric='cosine' )\n",
    "knn.fit(train_data_features, train_data['tag'])\n",
    "\n",
    "# predict\n",
    "predict(count_vectorizer, logreg, test_data)\n",
    "predict(count_vectorizer, svc, test_data)\n",
    "predict(count_vectorizer, rf, test_data)\n",
    "predict(count_vectorizer, knn, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lf/PycharmProjects/ASsmell/venv/lib/python3.8/site-packages/sklearn/linear_model/logistic.py:430: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  warnings.warn(\"Default solver will be changed to 'lbfgs' in 0.22. \"\n",
      "/Users/lf/PycharmProjects/ASsmell/venv/lib/python3.8/site-packages/sklearn/linear_model/logistic.py:430: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  warnings.warn(\"Default solver will be changed to 'lbfgs' in 0.22. \"\n",
      "/Users/lf/PycharmProjects/ASsmell/venv/lib/python3.8/site-packages/sklearn/linear_model/logistic.py:430: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  warnings.warn(\"Default solver will be changed to 'lbfgs' in 0.22. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.5488940279130152\n",
      "precision 0.5735693261469383\n",
      "recall 0.6191637630662021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lf/PycharmProjects/ASsmell/venv/lib/python3.8/site-packages/sklearn/linear_model/logistic.py:430: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  warnings.warn(\"Default solver will be changed to 'lbfgs' in 0.22. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 0.5900787690261426\n",
      "accuracy 0.5927077247646868\n",
      "precision 0.5910064412238325\n",
      "recall 0.5673635307781649\n",
      "F1 0.6133500672006184\n",
      "accuracy 0.607290652385589\n",
      "precision 0.6006396381396382\n",
      "recall 0.7785133565621372\n",
      "F1 0.6763406090458185\n",
      "accuracy 0.5572898409607271\n",
      "precision 0.5729075919773594\n",
      "recall 0.6253193960511033\n",
      "F1 0.595169121117664\n"
     ]
    }
   ],
   "source": [
    "# 10_fold_predict\n",
    "\n",
    "svc_10 = svm.SVC(gamma='scale')\n",
    "rf_10 = RandomForestClassifier(n_estimators=10)\n",
    "logreg_10 = linear_model.LogisticRegression(n_jobs=1, C=1e5)\n",
    "knn_10 = KNeighborsClassifier(n_neighbors=3, n_jobs=1, algorithm='brute', metric='cosine' )\n",
    "ten_cross_fold_predict(count_vectorizer, logreg_10, df)\n",
    "ten_cross_fold_predict(count_vectorizer, rf_10, df)\n",
    "ten_cross_fold_predict(count_vectorizer, svc_10, df)\n",
    "ten_cross_fold_predict(count_vectorizer, knn_10, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adapt',\n",
       " 'adapter',\n",
       " 'add',\n",
       " 'added',\n",
       " 'addin',\n",
       " 'adding',\n",
       " 'addition',\n",
       " 'additional',\n",
       " 'additionally',\n",
       " 'address']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer.get_feature_names()[80:90]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Character N-grams"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "n_gram_vectorizer = CountVectorizer(\n",
    "    analyzer=\"char\",\n",
    "    ngram_range=([2,5]),\n",
    "    tokenizer=None,    \n",
    "    preprocessor=None,                               \n",
    "    max_features=3000) \n",
    "\n",
    "train_data_features = n_gram_vectorizer.fit_transform(train_data[test_slice])\n",
    "logreg = linear_model.LogisticRegression(n_jobs=1, C=1e5)\n",
    "logreg = logreg.fit(train_data_features, train_data['tag'])\n",
    "predict(n_gram_vectorizer, logreg, test_data)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "n_gram_vectorizer.get_feature_names()[50:60]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
